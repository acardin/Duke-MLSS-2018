{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Assignment: Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Duke Community Standard](http://integrity.duke.edu/standard.html): By typing your name below, you are certifying that you have adhered to the Duke Community Standard in completing this assignment.**\n",
    "\n",
    "Name: Andrew Cardin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron\n",
    "\n",
    "Build a 2-layer MLP for MNIST digit classfication. Feel free to play around with the model architecture and see how the training time/performance changes, but to begin, try the following:\n",
    "\n",
    "Image (784 dimensions) -> fully connected layer (500 hidden units)  -> nonlinearity (ReLU) -> fully connected layer (100 hidden units) -> nonlinearity (ReLU) -> fully connected (256 hidden units) -> nonlinearity (ReLU) -> fully connected (10 hidden units) -> softmax"
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
# Import all necessary packages to workspace
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tqdm import trange
# Import mnist dataset for future manipulation
from tensorflow.examples.tutorials.mnist import input_data     ;
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True) ;
# Build a graph of operations for a two layer learning model
tf.reset_default_graph()
g   = tf.get_default_graph() ;# initialize graph, currently empty
# ------------------- Model tuning parameters ------------------- # 
n1     = 784  ;# -- layer 1 -- # (nodes) #500,300
n2     = 500  ;# -- layer 2 -- # (nodes) #300
n3     = 10   ;# -- Layer 3 -- # (nodes)
Nn     = 10   ;# nodes
d_r    = 0.2  ;# dropout rate
l_r    = 0.05 ;# -- Optimizer -- # learning rate for gradient descent 
ep_Num = 100  ;# Number of Epochs
# Pass in data
xx  = tf.placeholder(tf.float32, [None,784])                ;# data placeholder (input)
yy  = tf.placeholder(tf.int64, [None,10])                   ;# labels placeholder (output)
# ------------------ Layer #1 ------------------ # Linear Regression #1
W0  = tf.Variable(tf.truncated_normal([784,n1],stddev=0.1)) ;# assign random initial weights
b0  = tf.Variable(tf.truncated_normal([n1],stddev=0.1))     ;# assign random bias terms
y0  = tf.nn.relu(tf.add(tf.matmul(xx,W0),b0))               ;# apply relu to layer 1 result
# ------------------ Layer #2 ------------------ # Linear Regression #2
W1  = tf.Variable(tf.truncated_normal([n1,n2],stddev=0.1))  ;# assign random initial weights
b1  = tf.Variable(tf.truncated_normal([n2],stddev=0.1))     ;# assign random bias terms
y1  = tf.nn.relu(tf.add(tf.matmul(y0,W1),b1))               ;#
# ------------------ Layer #3 ------------------ # Linear Regression #3
#W2  = tf.Variable(tf.truncated_normal([n2,n3],stddev=0.1))  ;# assign random initial weights
#b2  = tf.Variable(tf.truncated_normal([n3],stddev=0.1))     ;# assign random bias terms
#y2  = tf.nn.relu(tf.add(tf.matmul(y1,W2),b2))               ;#
#p_y1 = tf.nn.softmax(y1)                                   ;#
# ------------------ Layer #3 ------------------ # Fully-connected Layer #1
#dense   = tf.layers.dense(inputs=y1, units=Nn, activation=tf.nn.relu)
#dropout = tf.layers.dropout(inputs=dense, rate=d_r)
#y2      = tf.layers.dense(inputs=dropout, units=n3)
# Define loss and optimization scheme
c_ent          = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y1, labels=yy)) ;# loss metric, the cross entropy of the loss, claculated by softmax
train_step     = tf.train.GradientDescentOptimizer(l_r).minimize(c_ent)                           ;# Here we're minimizing loss with gradient descent at a rate l_r
initialize_all = tf.global_variables_initializer()
# Create session object and initialize
sess = tf.Session()
sess.run(initialize_all)
# Train model
for epoch in trange(ep_Num):
    for which_batch in range(550):
        batch_xs = mnist.train.images[which_batch*100:(which_batch+1)*100]
        batch_ys = mnist.train.labels[which_batch*100:(which_batch+1)*100]
        sess.run(train_step, feed_dict={xx: batch_xs, yy: batch_ys})
# Test model
got_right = tf.equal(tf.argmax(y2, 1), tf.argmax(yy, 1))
accuracy  = tf.reduce_mean(tf.cast(got_right, tf.float32))
print('Test accuracy: {0}'.format(sess.run(accuracy, 
       feed_dict={xx: mnist.test.images, yy: mnist.test.labels})))
# Close session to finish
sess.close()
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
